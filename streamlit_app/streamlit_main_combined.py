# streamlit_app/app.py
import streamlit as st
import httpx
import base64
import asyncio
from google import genai
from google.genai import types
import os
import json
import random
#from functools import reduce
# Bring in the Agentic code with Langgraph
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph.message import add_messages
# Chatbot sepcific imports
from langgraph.graph import StateGraph, START, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages.ai import AIMessage
# My special import
from core_in import ImmoSelectorState, BARISTABOT_SYSINT, WELCOME_MSG
# Set Streamlit to wide layout
st.set_page_config(
    page_title="SmartSearchAPI fÃ¼r Kawohls Immobilien",
    page_icon="rocket",
    layout="wide",
)

# API configuration
COMBINED_API_URL = "http://vector_search_service:8000/api/v1/combined_vector_search"
API_KEY = "api key"
GOOGLE_API_KEY = "google api key"
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

# Function to perform combined search
async def perform_search(input_data: str, input_type="text"):
    payload = {}
    params = {"api_key": API_KEY}

    if input_type == "text" and input_data:
        payload["text"] = input_data
    elif input_type == "image" and input_data:
        # Read and encode the image file as base64
        image_bytes = input_data.read()
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")
        payload["image"] = image_base64
    else:
        st.error("Invalid input type or missing input.")
        return None

    # Perform the asynchronous request using httpx
    async with httpx.AsyncClient() as client:
        response = await client.post(COMBINED_API_URL, json=payload, params=params, timeout=90.0)
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"Search failed: {response.text}")
            return None
# Function to perform search using Google GenAI
# Function to perform combined search
def perform_search_genai(search_text_for_semantic_search: str) -> dict:
    """Perform a search using the combined API.
    Args:
        search_text_for_semantic_search (str): The text to search for generated by llm."""

    print("Performing search with input data:", input_data)
    payload = {}
    params = {"api_key": API_KEY}
    input_type="text"

    if input_type == "text" and input_data:
        payload["text"] = input_data
    elif input_type == "image" and input_data:
        # Read and encode the image file as base64
        image_bytes = input_data.read()
        image_base64 = base64.b64encode(image_bytes).decode("utf-8")
        payload["image"] = image_base64
    else:
        st.error("Invalid input type or missing input.")
        return None

    # Perform the asynchronous request using httpx
    with httpx.Client() as client:
        response = client.post(COMBINED_API_URL, json=payload, params=params, timeout=90.0)
        if response.status_code == 200:
            return response.json()
        else:
            st.error(f"Search failed: {response.text}")
            return None
#  Bringing in the Agentic code from Langgraph------------------------------------------------------------------------------------------
# Try using different models. The Gemini 2.0 flash model is highly
# capable, great with tools, and has a generous free tier. If you
# try the older 1.5 models, note that the `pro` models are better at
# complex multi-tool cases like this, but the `flash` models are
# faster and have more free quota.
# Check out the features and quota differences here:
#  - https://ai.google.dev/gemini-api/docs/models/gemini
llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash")

def human_node(state: ImmoSelectorState) -> ImmoSelectorState:
    """Display the last model message to the user, and receive the user's input."""
    last_msg = state["messages"][-1]
    print("Model:", last_msg.content)

    user_input = st.text_input("Your message:", label_visibility="collapsed", placeholder="Type your message here...")

    # If it looks like the user is trying to quit, flag the conversation
    # as over.
    if user_input in {"q", "quit", "exit", "goodbye"}:
        state["finished"] = True

    return state | {"messages": [("user", user_input)]}


def chatbot_with_welcome_msg(state: ImmoSelectorState) -> ImmoSelectorState:
    """The chatbot itself. A simple wrapper around the model's own chat interface."""
    if state["messages"]:
        # If there are messages, continue the conversation with the Gemini model.
        new_output = llm.invoke([BARISTABOT_SYSINT] + state["messages"])
    else:
        # If there are no messages, start the conversation with the welcome message.
        new_output = AIMessage(content=WELCOME_MSG)
    return state | {"messages": [new_output]}

def chatbot(state: ImmoSelectorState) -> ImmoSelectorState:
    """The chatbot itself. A simple wrapper around the model's own chat interface."""
    message_history = [BARISTABOT_SYSINT] + state["messages"]
    return {"messages": [llm.invoke(message_history)]}


# Set up the initial graph based on our state definition.
graph_builder = StateGraph(ImmoSelectorState)

# Add the chatbot function to the app graph as a node called "chatbot".
graph_builder.add_node("chatbot", chatbot)

# Define the chatbot node as the app entrypoint.
graph_builder.add_edge(START, "chatbot")

chat_graph = graph_builder.compile()


# Bringing in the Agentic code
db_tools = [perform_search_genai]
instruction = """You are a helpful chatbot that can assist users in finding relevant real estate information.
Use the information provided in the prompt to generate detailed and accurate answers to the user's queries about real estate. Ensure your responses are clear, concise, and informative.
Use the german Language to answer   . You will take the users input and use the tools provided to gather information.once you have the information you need you will answer the user use the function
perform_search_genai to get the information you need. you can provide the user inputed text to generate search text and give it as the parameter to the function. perform_search_genai to get the information you need. 
. You can provide the user inputed image to generate search text and give it as the parameter to the function. perform_search_genai to get the information you need. 
Make sure that you do not provide duplicate information to the user. because in the user given prompt there can be duplicates """
client = genai.Client(api_key=GOOGLE_API_KEY)

chat = client.chats.create(
    model="gemini-2.0-flash",
    config=types.GenerateContentConfig(
        system_instruction=instruction,
        tools=db_tools,
    ),
)

# Display search results as smaller tiles
def display_result_tile(result, index):
    with st.container():
        # Group images into a gallery format with clickable tiles
        image_data = result.get("longImage") or result.get("onlineImage")
        if isinstance(image_data, dict) and image_data.get("values"):
            image_urls = [item.get("uri") for item in image_data.get("values") if item.get("uri")]

            # Display images in a grid format (e.g., 4 columns)
            num_columns = 8
            grouped_images = [image_urls[i:i + num_columns] for i in range(0, len(image_urls), num_columns)]

            for group in grouped_images:
                cols = st.columns(num_columns)
                for col, image_url in zip(cols, group):
                    if image_url:
                        with col:
                            st.image(image_url, use_container_width=True)


# Convert the image to base64
def get_base64_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode()

# Get the base64 string of the image
logo_base64 = get_base64_image("streamlit_app/logo22.webp")

# Add logo
logo = "streamlit_app/final_logo.png"
left_co, cent_co, last_co = st.columns([1, 3, 1])
with cent_co:
    st.markdown(
        f"""
        <div style="display: flex; flex-direction: column; align-items: center;">
            <img src="data:image/png;base64,{logo_base64}" width="250">
            <h1 style="margin-top: 10px; text-align: center;">Kawohls KI Agent von Smartsearch</h1>
            <p style="margin-top: 5px; font-size: 18px; text-align: center; color: #B87333;">
                Gebe dein Immobilienbeschreibungen ein oder lade ein Bild hoch um die Beste Immobilien  in Stralsund zu finden.
            </p>
        </div>
        """,
        unsafe_allow_html=True
    )

# Chat interface
st.markdown("---")
st.subheader("Kawohls KI")
chat_input = st.text_input("Frage an den KI Immobilien Suche von Kawohls: oder lade ein Bild hoch", label_visibility="collapsed")
image_file_ai = st.file_uploader("Lade ein Bild hoch", type=["jpg", "png"], label_visibility="collapsed")


if st.button("Suchen"):
    if chat_input or image_file_ai:
        info_for_chat = asyncio.run(perform_search(input_data=image_file_ai, input_type="image")) if image_file_ai else asyncio.run(perform_search(input_data=chat_input, input_type="text"))
        unique_data = {individual_content['id']: individual_content  for individual_content in info_for_chat["content"]}
        info_to_pass = unique_data
        if image_file_ai:
            st.write("Such Bild:")
            st.image(image_file_ai, width=150)  # Display the image in a smaller size
        elif chat_input:
            st.write("Such Text:")
            st.markdown(f"**<h4 style='text-align: center;'>{chat_input}</h4>**", unsafe_allow_html=True)

        for index, result in enumerate(unique_data.values()):
            reason = " You have to explain why this result is relevant to the user.and it should be concise with rich details and reason ,also try to include the location of the property in the text, and other details as well use small bullet points if necessary "
            response_per_image = chat.send_message(chat_input + reason + str(result))
            # Display the headline as a larger, bold caption below the images
            headline = result.get("headline", {}).get("values", ["No Title"])[0]
            addresses = result.get("addresses", {}).get("values", ["No Address"])[0]
            text_location = result.get("textLocation", {}).get("values", ["No Address"])[0]
            st.markdown(f"**<h4 style='text-align: center;'>{index + 1}. {headline}</h4>**", unsafe_allow_html=True)
            #st.markdown(f"**<h4 style='text-align: center;'>{index + 1}. {response_per_image.text}</h4>**", unsafe_allow_html=True)
            st.write(response_per_image.text)
            #st.text_input("Bitte geben Sie Ihre Frage ein", Key="user_question1")
            
            random.seed(42)  # Set a random seed for reproducibility
            # Generate a unique ID for the text input field
            unique_id = random.SystemRandom().randint(1, 1000000)
            # Display the text input field with a unique key
            user_question = st.text_input("Haben Sie weiter Fragen zu diesem Objekt?", key=f"user_question{unique_id}")
            if st.button("Fragen", key=f"User button response{unique_id}") and user_question:
                # Perform the search with the user's question
                if state["messages"]:
                    # If there are messages, continue the conversation with the Gemini model.
                    state["messages"].append(("user", user_question))
                    state = chat_graph.invoke(state)
                    st.write(state["messages"][-1].content)

                else:
                    # If there are no messages, start the conversation with the welcome message.
                    state = chat_graph.invoke({"messages": [BARISTABOT_SYSINT + response_per_image.text + user_question ]})
                    st.write(state["messages"][-1].content)
                # Display the messages from the state

            display_result_tile(result, index)
    
    elif chat_input and image_file_ai:
        # Perform the search with both text and image
        info_for_chat = asyncio.run(perform_search(input_data=chat_input, input_type="text"))
        response_image = asyncio.run(perform_search(input_data=image_file_ai, input_type="image"))
        unique_data_text = {individual_content['id']: individual_content  for individual_content in info_for_chat["content"]}
        unique_data_image = {individual_content['id']: individual_content  for individual_content in response_image["content"]}
        # Combine the two dictionaries, ensuring unique keys
        unique_data = {**unique_data_text, **unique_data_image}

        info_to_pass = unique_data
        st.write("Such Bild:")
        st.image(image_file_ai, width=150)  # Display the image in a smaller size
        st.write("Such Text:")

        for index, result in enumerate(unique_data.values()):
            reason = " You have to explain why this result is relevant to the user.and it should be concise with rich details and reason ,also try to include the location of the property in the text, and other details as well use small bullet points if necessary "
            response_per_image = chat.send_message(chat_input + reason + str(result))
            # Display the headline as a larger, bold caption below the images
            headline = result.get("headline", {}).get("values", ["No Title"])[0]
            addresses = result.get("addresses", {}).get("values", ["No Address"])[0]
            text_location = result.get("textLocation", {}).get("values", ["No Address"])[0]
            st.markdown(f"**<h4 style='text-align: center;'>{index + 1}. {headline}</h4>**", unsafe_allow_html=True)
            st.write(response_per_image.text)
            display_result_tile(result, index)
    else:
        st.error("Please enter a message to chat.")


#------------------------------------------------------------------------------------------



